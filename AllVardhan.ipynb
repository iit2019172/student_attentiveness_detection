{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0d5e2c-7dff-4fdf-a858-feea3f10b299",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Issues:\n",
    "1. Noface count and multiple count for each frame happening\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f19125be-4634-4de8-a40f-59c098552eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from face_detector import get_face_detector, find_faces, draw_faces\n",
    "from face_landmarks import get_landmark_model, detect_marks, draw_marks\n",
    "from deepface import DeepFace\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47386dbb-e78e-486e-bf7a-87f97cec1d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_model = get_face_detector()\n",
    "landmark_model = get_landmark_model()\n",
    "outer_points = [[49, 59], [50, 58], [51, 57], [52, 56], [53, 55]]\n",
    "d_outer = [0]*5\n",
    "inner_points = [[61, 67], [62, 66], [63, 65]]\n",
    "d_inner = [0]*3\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "noface_count = 0\n",
    "multiple_faces_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58be2877-3649-451a-8414-56e1648ce587",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12136/4110985155.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrects\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect_marks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlandmark_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mdraw_marks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             cv2.putText(img, 'Press r to record Mouth distances', (30, 30), font,\n",
      "\u001b[1;32m~\\ivp-online-proctoring-system\\face_landmarks.py\u001b[0m in \u001b[0;36mdetect_marks\u001b[1;34m(img, model, face)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m   \"\"\"\n\u001b[1;32m--> 271\u001b[1;33m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[0;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    284\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\env2\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m   \u001b[1;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 308\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    309\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    rects = find_faces(img, face_model)\n",
    "    \n",
    "    if len(rects)>1:\n",
    "        multiple_faces_count += 1\n",
    "        cv2.putText(img, 'Alert! multiple faces detected for '+str(multiple_faces_count)+' times', (30, 60), font,\n",
    "                    1, (0, 255, 255), 2)\n",
    "    elif len(rects)==0:\n",
    "        noface_count+=1\n",
    "        cv2.putText(img, 'Alert! No faces detected for '+str(noface_count)+' times', (30, 60), font,\n",
    "                    1, (0, 255, 255), 2)\n",
    "    else:\n",
    "            rect = rects[0]\n",
    "            shape = detect_marks(img, landmark_model, rect)\n",
    "            draw_marks(img, shape)\n",
    "            cv2.putText(img, 'Press r to record Mouth distances', (30, 30), font,\n",
    "                        1, (0, 255, 255), 2)\n",
    "            \n",
    "    cv2.imshow(\"Output\", img)\n",
    "            \n",
    "    if cv2.waitKey(1) & 0xFF == ord('r'):\n",
    "        for i in range(100):\n",
    "            for i, (p1, p2) in enumerate(outer_points):\n",
    "                d_outer[i] += shape[p2][1] - shape[p1][1]\n",
    "            for i, (p1, p2) in enumerate(inner_points):\n",
    "                d_inner[i] += shape[p2][1] - shape[p1][1]\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "d_outer[:] = [x / 100 for x in d_outer]\n",
    "d_inner[:] = [x / 100 for x in d_inner]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e8fc05-5605-41d1-93e0-3e6c7bf113f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Face recognition:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "090d8e2c-1a91-480e-b9e3-cc92e492923d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n",
      "Mouth open\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    ret, img = cap.read()\n",
    "    rects = find_faces(img, face_model)\n",
    "    for rect in rects:\n",
    "        shape = detect_marks(img, landmark_model, rect)\n",
    "        cnt_outer = 0\n",
    "        cnt_inner = 0\n",
    "        draw_marks(img, shape[48:])\n",
    "        for i, (p1, p2) in enumerate(outer_points):\n",
    "            if d_outer[i] + 3 < shape[p2][1] - shape[p1][1]:\n",
    "                cnt_outer += 1 \n",
    "        for i, (p1, p2) in enumerate(inner_points):\n",
    "            if d_inner[i] + 2 <  shape[p2][1] - shape[p1][1]:\n",
    "                cnt_inner += 1\n",
    "        if cnt_outer > 3 and cnt_inner > 2:\n",
    "            print('Mouth open')\n",
    "            cv2.putText(img, 'Mouth open', (30, 30), font,\n",
    "                    1, (0, 255, 255), 2)\n",
    "        # show the output image with the face detections + facial landmarks\n",
    "    cv2.imshow(\"Output\", img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04ebcf-f55c-4277-946f-c80fa6342273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e658a154-858d-4355-a2b5-08825b79c2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6731a9-9c52-401a-8a69-718499c568f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
